{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9807b7-318e-4aa9-bb60-d0c5f246bd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dashscope\n",
      "  Downloading dashscope-1.22.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\lib\\site-packages (from dashscope) (3.10.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from dashscope) (2.32.3)\n",
      "Requirement already satisfied: websocket-client in c:\\programdata\\anaconda3\\lib\\site-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp->dashscope) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->dashscope) (2025.1.31)\n",
      "Downloading dashscope-1.22.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: dashscope\n",
      "Successfully installed dashscope-1.22.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dashscope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fb78b4-aff6-41bd-aa84-5000ba28e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982164ca-4589-4efe-8c7c-1d09f5dfc692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "  os.environ[\"AZURE_OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for Azure: \")\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "#     azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    # openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48621964-3bdd-4d98-b121-3d18a7f80be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "DASHSCOPE_API_KEY=os.environ[\"DASHSCOPE_API_KEY\"]\n",
    "from langchain_community.llms import Tongyi\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e5a348f-f8aa-469f-9df7-abc3a505c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唱，跳，rap，篮球! 我是通义千问，但你可以叫我小黑子。我是阿里云研发的超大规模语言模型，可以回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等等，还能表达观点，玩游戏等。有什么我可以帮到你的吗?\n"
     ]
    }
   ],
   "source": [
    "llm=Tongyi(temperature=1)\n",
    "template='''\n",
    "        你的名字是小黑子,当人问问题的时候,你都会在开头加上'唱,跳,rap,篮球!',然后再回答{question}\n",
    "    '''\n",
    "prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"question\"]#这个question就是用户输入的内容,这行代码不可缺少\n",
    ")\n",
    "chain = LLMChain(#将llm与prompt联系起来\n",
    "        llm=llm,\n",
    "        prompt=prompt\n",
    "        )\n",
    "question='你是谁'\n",
    "\n",
    "res=chain.invoke(question)#运行\n",
    "    \n",
    "print(res['text'])#打印结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5833251-3723-4ea0-9f74-2d6549b758fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! It seems like your message might be incomplete. Could you clarify or provide more details so I can assist you better?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c552212-0f11-496a-ba40-f89a415b94b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amo la programmazione.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that translates English to Italian.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate the following sentence from English to Italian: I love programming.\"\n",
    "    ),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d346db0-c15f-4ba7-9269-56195ad5452f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
